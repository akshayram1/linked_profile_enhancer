#!/usr/bin/env python3
"""
Test script to verify LinkedIn URL scraping fixes
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from agents.scraper_agent import ScraperAgent
from agents.orchestrator import ProfileOrchestrator

def test_url_handling():
    """Test that different URLs are handled correctly"""
    
    print("ğŸ§ª Testing LinkedIn URL handling...")
    
    # Test URLs
    test_urls = [
        "https://www.linkedin.com/in/test-user-1/",
        "https://www.linkedin.com/in/test-user-2/", 
        "linkedin.com/in/different-user"
    ]
    
    scraper = ScraperAgent()
    
    for url in test_urls:
        print(f"\nğŸ” Testing URL: {url}")
        profile_data = scraper.extract_profile_data(url)
        
        print(f"âœ… Profile Name: {profile_data.get('name', 'N/A')}")
        print(f"âœ… Profile URL: {profile_data.get('url', 'N/A')}")
        print(f"âœ… Scraped At: {profile_data.get('scraped_at', 'N/A')}")
        
        # Verify the URL is correctly stored
        if profile_data.get('url') != url and not profile_data.get('url', '').startswith('https://'):
            expected_url = 'https://' + url if not url.startswith('http') else url
            if profile_data.get('url') == expected_url:
                print("âœ… URL normalization working correctly")
        
        print("-" * 50)

def test_orchestrator():
    """Test the orchestrator with fresh data"""
    
    print("\nğŸ­ Testing Orchestrator...")
    
    orchestrator = ProfileOrchestrator()
    
    # Test with force refresh
    test_url = "https://www.linkedin.com/in/example-user/"
    
    print(f"ğŸ”„ Testing with force refresh for: {test_url}")
    result = orchestrator.enhance_profile(test_url, force_refresh=True)
    
    print("âœ… Orchestrator test completed")
    print(f"ğŸ“ Result length: {len(result)} characters")

if __name__ == "__main__":
    print("ğŸš€ Starting LinkedIn URL Scraping Tests")
    print("=" * 60)
    
    try:
        test_url_handling()
        test_orchestrator()
        
        print("\nâœ… All tests completed!")
        print("\nğŸ“‹ Summary of fixes:")
        print("â€¢ Added URL change detection in Streamlit")
        print("â€¢ Added session state clearing when URL changes")
        print("â€¢ Enhanced logging in scraper agent")
        print("â€¢ Added cache clearing functionality")
        print("â€¢ Fixed URL normalization")
        
    except Exception as e:
        print(f"âŒ Test failed: {str(e)}")
        import traceback
        traceback.print_exc()
